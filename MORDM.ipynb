{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5b07ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Room for the river: Gorssel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3696bde3-f3c6-4cc2-9345-a20bf01784a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c5fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import sys\n",
    "\n",
    "from ema_workbench import (Model, CategoricalParameter,ScalarOutcome, IntegerParameter, RealParameter,\n",
    "                           MultiprocessingEvaluator, ema_logging, Constant, Policy, Scenario,\n",
    "                           perform_experiments, SequentialEvaluator,Constraint)\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume, EpsilonProgress,GenerationalBorg)\n",
    "from ema_workbench.em_framework.evaluators import (perform_experiments,BaseEvaluator)\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging\n",
    "from ema_workbench.analysis import plotting, plotting_util, parcoords, feature_scoring, prim\n",
    "from ema_workbench import load_results \n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import functools\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550506d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def evaluate_diversity_single(indices, distances, weight=0.5, distance='euclidean'):\n",
    "    '''\n",
    "    takes the outcomes and selected scenario set (decision variables), \n",
    "    returns a single 'diversity' value for the scenario set.\n",
    "    outcomes : outcomes dictionary of the scenario ensemble\n",
    "    decision vars : indices of the scenario set\n",
    "    weight : weight given to the mean in the diversity metric. If 0, only minimum; if 1, only mean\n",
    "    '''\n",
    "    i, j = [e for e in zip(*itertools.combinations(indices, 2))]\n",
    "    subset_distances = distances[i, j]\n",
    "    minimum = np.min(subset_distances)\n",
    "    mean = np.mean(subset_distances)\n",
    "    diversity = (1-weight)*minimum + weight*mean\n",
    "    \n",
    "    return [diversity]\n",
    "\n",
    "\n",
    "def find_maxdiverse_scenarios(distances, combinations):\n",
    "    scores = []\n",
    "    for indices in combinations:\n",
    "        diversity = evaluate_diversity_single(indices, distances)\n",
    "        scores.append((diversity, indices))\n",
    "\n",
    "    return scores\n",
    "\n",
    "def optimize(scenario, nfe, model, converge_metrics, epsilons):\n",
    "    with SequentialEvaluator(model) as evaluator:\n",
    "    #with MultiprocessingEvaluator(model) as evaluator:\n",
    "        results, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "                                     convergence=convergence_metrics,\n",
    "                                     epsilons=epsilons,\n",
    "                                     reference=scenario)\n",
    "    return results, convergence\n",
    "\n",
    "def entries_to_remove(entries, the_dict):\n",
    "    for key in entries:\n",
    "        if key in the_dict:\n",
    "            del the_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8eca0e-9617-4c49-a750-d94729925605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the correct dataframes of a long run \n",
    "df_experiments_s1000_p10 = pd.read_csv(\"df_experiments_s1000_p10.csv\")\n",
    "df_outcomes_s1000_p10 = pd.read_csv(\"df_outcomes_s1000_p10.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad865d25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set experiments and outcomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc263f97-3d16-456e-8d4f-5bcc31dc5224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 54)\n",
      "(10000, 18)\n"
     ]
    }
   ],
   "source": [
    "print(df_experiments_s1000_p10.shape) \n",
    "print(df_outcomes_s1000_p10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d11f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run MORDM with the long run as imported, copy the data here so it doesn't have to be loaded in again \n",
    "\n",
    "experiments = df_experiments_s1000_p10.copy()\n",
    "outcomes = df_outcomes_s1000_p10.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08b309-3479-494b-8b3f-71253c6dbcea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scenario Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c42931-5537-49df-866d-3f7484806754",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Choose outcomes of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68278c3a-8e40-4f72-913b-c44a0ad23bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random selecteren van outcomes \n",
    "set_seed = 1234567 \n",
    "random.seed(set_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57189e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#outcomes[['A.4_Expected Annual Damage','A.4_Dike Investment Costs', 'A.4_Expected Number of Deaths','RfR Total Costs','Expected Evacuation Costs']]\n",
    "number_of_outcomes = 173 #too much: 10000,1000,500,175,174 goes well: 150, 172,173\n",
    "\n",
    "outcomes_of_interest = outcomes.sample(n=number_of_outcomes, random_state = set_seed)\n",
    "\n",
    "y= (outcomes.index.isin(outcomes_of_interest.index))\n",
    "\n",
    "#y = (outcomes['A.4_Expected Annual Damage']< max_expected_annual_damage)&( outcomes['Expected Evacuation Costs']<max_evacuation_costs)\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9db12a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiments_of_interest = experiments.loc[y]\n",
    "outcomes_df = pd.DataFrame({k:v[y] for k,v in outcomes.items()})\n",
    "\n",
    "#normalize outcomes on unit interval to ensure equal weighting of outcomes\n",
    "x = outcomes_df.values \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "normalized_outcomes = pd.DataFrame(x_scaled, columns=outcomes_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b13012-5b88-46f1-aab6-3983ce71a46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A.0_ID flood wave shape</th>\n",
       "      <th>A.1_Bmax</th>\n",
       "      <th>A.1_Brate</th>\n",
       "      <th>A.1_pfail</th>\n",
       "      <th>A.2_Bmax</th>\n",
       "      <th>A.2_Brate</th>\n",
       "      <th>A.2_pfail</th>\n",
       "      <th>A.3_Bmax</th>\n",
       "      <th>A.3_Brate</th>\n",
       "      <th>...</th>\n",
       "      <th>A.4_DikeIncrease 0</th>\n",
       "      <th>A.4_DikeIncrease 1</th>\n",
       "      <th>A.4_DikeIncrease 2</th>\n",
       "      <th>A.5_DikeIncrease 0</th>\n",
       "      <th>A.5_DikeIncrease 1</th>\n",
       "      <th>A.5_DikeIncrease 2</th>\n",
       "      <th>EWS_DaysToThreat</th>\n",
       "      <th>scenario</th>\n",
       "      <th>policy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>31</td>\n",
       "      <td>321.087153</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.339356</td>\n",
       "      <td>94.394245</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.251813</td>\n",
       "      <td>194.392592</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>78</td>\n",
       "      <td>58.368824</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.585965</td>\n",
       "      <td>112.850913</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.609583</td>\n",
       "      <td>109.966911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>44</td>\n",
       "      <td>40.567925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.706251</td>\n",
       "      <td>233.216342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140394</td>\n",
       "      <td>276.830567</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>116</td>\n",
       "      <td>221.408402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881096</td>\n",
       "      <td>96.943702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.481245</td>\n",
       "      <td>238.827274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>707</td>\n",
       "      <td>66</td>\n",
       "      <td>349.252960</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.565601</td>\n",
       "      <td>54.489702</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.399284</td>\n",
       "      <td>266.496110</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>717</td>\n",
       "      <td>0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  A.0_ID flood wave shape    A.1_Bmax  A.1_Brate  A.1_pfail  \\\n",
       "106         106                       31  321.087153       10.0   0.339356   \n",
       "336         336                       78   58.368824        1.5   0.585965   \n",
       "401         401                       44   40.567925        1.0   0.706251   \n",
       "490         490                      116  221.408402        1.0   0.881096   \n",
       "707         707                       66  349.252960        1.5   0.565601   \n",
       "\n",
       "       A.2_Bmax  A.2_Brate  A.2_pfail    A.3_Bmax  A.3_Brate  ...  \\\n",
       "106   94.394245        1.5   0.251813  194.392592       10.0  ...   \n",
       "336  112.850913       10.0   0.609583  109.966911        1.0  ...   \n",
       "401  233.216342        1.0   0.140394  276.830567        1.5  ...   \n",
       "490   96.943702        1.0   0.481245  238.827274        1.0  ...   \n",
       "707   54.489702       10.0   0.399284  266.496110       10.0  ...   \n",
       "\n",
       "     A.4_DikeIncrease 0  A.4_DikeIncrease 1  A.4_DikeIncrease 2  \\\n",
       "106                   9                   3                   7   \n",
       "336                   9                   3                   7   \n",
       "401                   9                   3                   7   \n",
       "490                   9                   3                   7   \n",
       "707                   9                   3                   7   \n",
       "\n",
       "     A.5_DikeIncrease 0  A.5_DikeIncrease 1  A.5_DikeIncrease 2  \\\n",
       "106                   6                   9                  10   \n",
       "336                   6                   9                  10   \n",
       "401                   6                   9                  10   \n",
       "490                   6                   9                  10   \n",
       "707                   6                   9                  10   \n",
       "\n",
       "     EWS_DaysToThreat  scenario  policy     model  \n",
       "106                 2       116       0  dikesnet  \n",
       "336                 2       346       0  dikesnet  \n",
       "401                 2       411       0  dikesnet  \n",
       "490                 2       500       0  dikesnet  \n",
       "707                 2       717       0  dikesnet  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes_of_interest.head()\n",
    "experiments_of_interest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058a5b0d-b94b-4485-92ce-d79c4d9af06f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foutmelding: \n",
    "#The kernel for Documents/GitHub/EPA1361_group16/MORDM.ipynb appears to have died. It will restart automatically. \n",
    "\n",
    "n_scen = experiments.loc[y].shape[0]\n",
    "indices = range(n_scen)\n",
    "set_size = 5\n",
    "\n",
    "n_scen\n",
    "combinations = itertools.combinations(indices, set_size)\n",
    "combinations = list(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e039b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled_combinations = random.sample(combinations, 100) #In case there are too many combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = squareform(pdist(normalized_outcomes.values))\n",
    "\n",
    "cores = os.cpu_count()\n",
    "partial_function = functools.partial(find_maxdiverse_scenarios, distances)\n",
    "\n",
    "\n",
    "#Difference ProcessPool en ThreadPool \n",
    "# https://superfastpython.com/threadpoolexecutor-vs-processpoolexecutor/#Comparison_of_ThreadPoolExecutor_vs_ProcessPoolExecutor\n",
    "#with ProcessPoolExecutor(max_workers=cores) as executor:\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=cores) as executor:\n",
    "    worker_data = np.array_split(combinations, cores)\n",
    "    results = [e for e in executor.map(partial_function, worker_data)]\n",
    "    results = list(itertools.chain.from_iterable(results))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4273343",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort(key=lambda entry:entry[0], reverse=True)\n",
    "most_diverse = results[0]\n",
    "most_diverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68bfcf2-9b99-4c2a-8d69-878cee4f1e32",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create scenarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98427f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = experiments.loc[most_diverse[1], ['A.0_ID flood wave shape', 'A.1_Bmax', 'A.1_Brate', 'A.1_pfail',\n",
    "       'A.2_Bmax', 'A.2_Brate', 'A.2_pfail', 'A.3_Bmax', 'A.3_Brate',\n",
    "       'A.3_pfail', 'A.4_Bmax', 'A.4_Brate', 'A.4_pfail', 'A.5_Bmax',\n",
    "       'A.5_Brate', 'A.5_pfail', 'discount rate 0', 'discount rate 1',\n",
    "       'discount rate 2', '0_RfR 0', '0_RfR 1', '0_RfR 2', '1_RfR 0',\n",
    "       '1_RfR 1', '1_RfR 2', '2_RfR 0', '2_RfR 1', '2_RfR 2', '3_RfR 0',\n",
    "       '3_RfR 1', '3_RfR 2', '4_RfR 0', '4_RfR 1', '4_RfR 2',\n",
    "       'A.1_DikeIncrease 0', 'A.1_DikeIncrease 1', 'A.1_DikeIncrease 2',\n",
    "       'A.2_DikeIncrease 0', 'A.2_DikeIncrease 1', 'A.2_DikeIncrease 2',\n",
    "       'A.3_DikeIncrease 0', 'A.3_DikeIncrease 1', 'A.3_DikeIncrease 2',\n",
    "       'A.4_DikeIncrease 0', 'A.4_DikeIncrease 1', 'A.4_DikeIncrease 2',\n",
    "       'A.5_DikeIncrease 0', 'A.5_DikeIncrease 1', 'A.5_DikeIncrease 2',\n",
    "       'EWS_DaysToThreat', 'scenario', 'policy', 'model']]\n",
    "scenarios = [Scenario(f\"{index}\", **row) for index, row in selected.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b962838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show what the scenarios entail \n",
    "\n",
    "# scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eea637-f18a-4c44-8e87-64940ab09de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_notscenario = ['0_RfR 0', '0_RfR 1', '0_RfR 2', '1_RfR 0', '1_RfR 1', '1_RfR 2', \n",
    "               '2_RfR 0', '2_RfR 1', '2_RfR 2', '3_RfR 0', '3_RfR 1', '3_RfR 2', '4_RfR 0', \n",
    "               '4_RfR 1', '4_RfR 2', 'A.1_DikeIncrease 0', 'A.1_DikeIncrease 1', 'A.1_DikeIncrease 2', \n",
    "              'A.2_DikeIncrease 0', 'A.2_DikeIncrease 1', 'A.2_DikeIncrease 2', 'A.3_DikeIncrease 0', \n",
    "              'A.3_DikeIncrease 1', 'A.3_DikeIncrease 2', 'A.4_DikeIncrease 0', 'A.4_DikeIncrease 1', \n",
    "              'A.4_DikeIncrease 2', 'A.5_DikeIncrease 0', 'A.5_DikeIncrease 1', 'A.5_DikeIncrease 2', \n",
    "              'EWS_DaysToThreat', 'scenario', 'policy','model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81fa6e-dc34-48eb-9694-65046189f864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create dictionary with only the uncertainties \n",
    "for i in range(0,5):\n",
    "    entries_to_remove(keys_notscenario, scenarios[i]) \n",
    "\n",
    "scenario_1 = scenarios[1]\n",
    "scenario_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afa300f-e067-422d-a466-4a09415e5b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290ce5b-6bef-4a6d-9820-602e9a86673c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3cbd6c-97d8-4e9b-9f3a-addbcefab1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "642ea2dc",
   "metadata": {},
   "source": [
    "# Mordm Run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef873f-6526-49a6-aed4-0e6cf49e400e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hypervolume determination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa601d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "results = []\n",
    "for scenario in scenarios:\n",
    "    convergence_metrics = [HyperVolume(minimum=[0,]*len(dike_model.outcomes), \n",
    "                                       maximum=[1000,]*len(dike_model.outcomes)),\n",
    "                           EpsilonProgress()]\n",
    "    epsilons = [0.1,]*len(dike_model.outcomes)\n",
    "    \n",
    "    results.append(optimize(scenario, 100, dike_model, convergence_metrics, epsilons))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56527143-b9bb-46e0-910a-8a7e905c7858",
   "metadata": {},
   "source": [
    "### Epsilon volume determination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b781079-10d8-44bb-b5b3-11ecae7a26c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results1 = evaluator.optimize(nfe=5e3, searchover='levers',\n",
    "                                  epsilons=[1,]*len(dike_model.outcomes),reference = scenario_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20754869-cf28-483c-ad7d-3393bf0dd551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2b019-f818-453b-8c95-3596aa7ed186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12d53482",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28787226",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "for i, (_, convergence) in enumerate(results):\n",
    "    ax1.plot(convergence.nfe, convergence.hypervolume, label=f'scenario {i}')\n",
    "    ax2.plot(convergence.nfe, convergence.epsilon_progress, label=f'scenario {i}')\n",
    "\n",
    "ax1.set_ylabel('hypervolume')\n",
    "ax1.set_xlabel('nfe')\n",
    "ax2.set_ylabel('$\\epsilon$ progress')\n",
    "ax2.set_xlabel('nfe')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d448824-e491-4a95-8a40-8235a70a3410",
   "metadata": {},
   "source": [
    "# The part of the notebook below is not of interest for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56edd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = iter(sns.color_palette())\n",
    "\n",
    "# data = results[0][0].iloc[:, 5::]\n",
    "# limits = parcoords.get_limits(data)\n",
    "\n",
    "# limits.loc[0, ['inertia', 'reliability']] = 1\n",
    "# limits.loc[0, 'max_P'] = 4 # max over results based on quick inspection not shown here\n",
    "# limits.loc[0, 'utility'] = 1 # max over results based on quick inspection not shown here\n",
    "# limits.loc[1, :] = 0\n",
    "# paraxes = parcoords.ParallelAxes(limits)\n",
    "\n",
    "\n",
    "# for i, (result, _) in enumerate(results):\n",
    "#     color = next(colors)\n",
    "#     data = result.iloc[:, 5::]\n",
    "#     paraxes.plot(data, label=f'scenario {i}', color=color)\n",
    "\n",
    "# paraxes.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e954faa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deep Uncertainty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab11f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #specify the policies \n",
    "\n",
    "policies = []\n",
    "for i, (result, _) in enumerate(results):\n",
    "    result = result.iloc[:, 0:5]\n",
    "    for j, row in result.iterrows():\n",
    "        policy = Policy(f'scenario {i} option {j}', **row.to_dict())\n",
    "        policies.append(policy)\n",
    "        \n",
    "# ## Our way: \n",
    "\n",
    "# #Identify policies based on open exploration \n",
    "\n",
    "# policies = [Policy('policy 1', **{'0_RfR 0':1,\n",
    "#                                   '0_RfR 1':1,\n",
    "#                                   '0_RfR 2':1,\n",
    "#                                   'A.1_DikeIncrease 0':5,\n",
    "#                                  'A.1_DikeIncrease 1':5}),\n",
    "#            Policy('policy 2', **{'4_RfR 0':1,\n",
    "#                                   '4_RfR 1':1,\n",
    "#                                   '4_RfR 2':1,\n",
    "#                                   'A.5_DikeIncrease 0':5}),\n",
    "#            Policy('policy 3', **{'1_RfR 0':1,\n",
    "#                                   '2_RfR 1':1,\n",
    "#                                   '3_RfR 2':1,\n",
    "#                                   'A.3_DikeIncrease 0':5})]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb508fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    reeevaluation_results = evaluator.perform_experiments(1000, policies=policies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5dd9b",
   "metadata": {},
   "source": [
    "Calculate both the maximum regret, and the domain criterion using the values provided in [Bartholomew and Kwakkel (2020)](https://doi.org/10.1016/j.envsoft.2020.104699). Ignore the max_P objective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7786cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiments, outcomes = reeevaluation_results\n",
    "\n",
    "#determine thresholds Based on table 4.3 from report \n",
    "\n",
    "max_expected_annual_damage = 9.28e+05\n",
    "#max_dike_investement = 10000\n",
    "max_number_deaths = 0.00009\n",
    "#max_rfr_costs = 200000\n",
    "#max_evacuation_costs = 5000\n",
    "\n",
    "#as defined earlier: \n",
    "thresholds = {'A.4_Expected Number of Deaths':max_number_deaths, \n",
    "              'A.4_Expected Annual Damage':max_expected_annual_damage}\n",
    "#, 'reliability':0.8}\n",
    "\n",
    "overall_scores = {}\n",
    "for policy in experiments.policy.unique():\n",
    "    logical = experiments.policy == policy\n",
    "    scores = {}\n",
    "    for k, v in outcomes.items():\n",
    "        try:\n",
    "            n = np.sum(v[logical]>=thresholds[k])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        scores[k] = n/1000 \n",
    "    overall_scores[policy] = scores\n",
    "        \n",
    "overall_scores = pd.DataFrame(overall_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = parcoords.get_limits(overall_scores)\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(overall_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb4a85",
   "metadata": {},
   "source": [
    "Alternative way?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d4d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_scores = {}\n",
    "# regret = []\n",
    "# for scenario in experiments.scenario.unique():\n",
    "#     logical = experiments.scenario==scenario\n",
    "#     temp_results = {k:v[logical] for k,v in outcomes.items()}\n",
    "#     temp_results = pd.DataFrame(temp_results)\n",
    "#     temp_experiments = experiments[experiments.scenario==scenario]\n",
    "        \n",
    "#     best = temp_results.max()\n",
    "#     best['max_P'] = temp_results.max_P.min()\n",
    "#     scenario_regret = a - best\n",
    "#     scenario_regret['policy'] = temp_experiments.policy.values    \n",
    "#     regret.append(scenario_regret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regret = pd.concat(regret)\n",
    "# maxregret = regret.groupby('policy').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc13d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limits = parcoords.get_limits(maxregret)\n",
    "# paraxes = parcoords.ParallelAxes(maxregret)\n",
    "# paraxes.plot(maxregret)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326cad9-fbbf-4622-aaad-0053c88b9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
